@article{ANNFundamentals,
	author = {Basheer, I.A and Hajmeer, M},
	doi = {10.1016/S0167-7012(00)00201-3},
	issn = {01677012},
	journal = {Journal of Microbiological Methods},
	month = {dec},
	number = {1},
	pages = {3--31},
	title = {{Artificial neural networks: fundamentals, computing, design, and application}},
	url = {http://ethosun2.unige.ch/etho5.10/pdf/basheer.hajmeer.2000.fundamentals.design.and.application.of.neural.networks.review.pdf},
	volume = {43},
	year = {2000}
}

@article{EvolvingANN,
	author={ {Xin Yao}},
	journal={Proceedings of the IEEE},
	title={Evolving artificial neural networks},
	year={1999},
	volume={87},
	number={9},
	pages={1423-1447},
	keywords={neural nets;learning (artificial intelligence);genetic algorithms;search problems;technological forecasting;neural networks;learning;evolutionary algorithms;connection weights;search operators;intelligent systems;Artificial neural networks;Intelligent systems;Competitive intelligence;Evolutionary computation;Artificial intelligence;Transfer functions;Computer networks;Intelligent networks;Algorithm design and analysis;Adaptive systems},
	doi={10.1109/5.784219},
	ISSN={1558-2256},
	month={Sep.},}

@book{ANNElements,
	title={Elements of artificial neural networks},
	author={Mehrotra, Kishan and Mohan, Chilukuri K and Ranka, Sanjay},
	year={1997},
	publisher={MIT press}
}

@article{ANNTutorial,
	author={A. K. {Jain} and {Jianchang Mao} and K. M. {Mohiuddin}},
	journal={Computer},
	title={Artificial neural networks: a tutorial},
	year={1996},
	volume={29},
	number={3},
	pages={31-44},
	keywords={neural nets;neurophysiology;character recognition;artificial neural networks;massively parallel systems;interconnected simple processors;basic biological neuron;artificial computational model;network architectures;learning processes;character recognition;ANN application;Tutorial;Artificial neural networks;Biology computing;Humans;Integrated circuit interconnections;Concurrent computing;Parallel processing;Biological neural networks;Computer architecture;Biological system modeling},
	doi={10.1109/2.485891},
	ISSN={1558-0814},
	month={March},}

@article{ANNBeginners,
	abstract = {The scope of this teaching package is to make a brief induction to Artificial Neural Networks (ANNs) for people who have no previous knowledge of them. We first make a brief introduction to models of networks, for then describing in general terms ANNs. As an application, we explain the backpropagation algorithm, since it is widely used and many other algorithms are derived from it. The user should know algebra and the handling of functions and vectors. Differential calculus is recommendable, but not necessary. The contents of this package should be understood by people with high school education. It would be useful for people who are just curious about what are ANNs, or for people who want to become familiar with them, so when they study them more fully, they will already have clear notions of ANNs. Also, people who only want to apply the backpropagation algorithm without a detailed and formal explanation of it will find this material useful. This work should not be seen as "Nets for dummies", but of course it is not a treatise. Much of the formality is skipped for the sake of simplicity. Detailed explanations and demonstrations can be found in the referred readings. The included exercises complement the understanding of the theory. The on-line resources are highly recommended for extending this brief induction.},
	author = {Gershenson, Carlos},
	eprinttype   = {arxiv},
	eprint = {cs/0308031},
	month = {aug},
	title = {{Artificial Neural Networks for Beginners}},
	url = {http://arxiv.org/abs/cs/0308031},
	year = {2003}
}

@techreport{principles,
	author = {Rosenblatt, Frank},
	institution = {Cornell Aeronautical Lab Inc Buffalo NY},
	title = {{Principles of neurodynamics. perceptrons and the theory of brain mechanisms}},
	url = {https://apps.dtic.mil/dtic/tr/fulltext/u2/256582.pdf},
	year = {1961}
}

@online{nielsen,
	author = {Nielsen, Michael A.},
	booktitle = {Determination Press},
	title = {{Neural Networks and Deep Learning}},
	url = {http://neuralnetworksanddeeplearning.com/},
	urldate = {2019-11-25},
	year = {2015}
}


@online{TDSperceptron1,
	author = {{Towards Data Science}},
	title = {{What the Hell is Perceptron? – Towards Data Science}},
	url = {https://towardsdatascience.com/what-the-hell-is-perceptron-626217814f53},
	urldate = {2019-11-25},
	year = {2017}
}


@online{TDSperceptron2,
	author = {{Towards Data Science}},
	title = {{Perceptron: The Artificial Neuron (An Essential Upgrade To The McCulloch-Pitts Neuron)}},
	url = {https://towardsdatascience.com/perceptron-the-artificial-neuron-4d8c70d5cc8d},
	urldate = {2019-11-25},
	year = {2018}
}


@online{MPerceptron1,
	author = {Medium},
	title = {{Build your own Neural Network — The story of Perceptron {\&} Sigmoid}},
	url = {https://medium.com/explore-artificial-intelligence/build-your-own-neural-network-1-the-story-of-perceptron-sigmoid-c9d1a9afdf95},
	urldate = {2019-12-03}
}


@book{Rojas1996,
author = {Rojas, Ra{\'{u}}l},
publisher = {Springer-Verlag},
title = {{Neural Networks - A Systematic Introduction}},
url = {https://page.mi.fu-berlin.de/rojas/neural/neuron.pdf},
year = {1996}
}

@online{mlp,
	author = {Nicholson, Chris},
	title = {{A Beginner's Guide to Multilayer Perceptrons (MLP) | Skymind}},
	url = {https://skymind.ai/wiki/multilayer-perceptron},
	urldate = {2019-12-07}
}

@online{TDSsigmoid,
	author = {{Towards Data Science}},
	mendeley-groups = {chap4},
	title = {{Sigmoid Neuron — Building Block of Deep Neural Networks}},
	url = {https://towardsdatascience.com/sigmoid-neuron-deep-neural-networks-a4cd35b629d7},
	urldate = {2019-12-08}
}

